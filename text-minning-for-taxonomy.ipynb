{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Text-mining-for-taxonomy\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator\n",
    "from typing import Annotated, List, Optional, TypedDict\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(\"tnt-llm\")\n",
    "\n",
    "class Doc(TypedDict):\n",
    "    id: str\n",
    "    content: str\n",
    "    summary: Optional[str]\n",
    "    explanation: Optional[str]\n",
    "    category: Optional[str]\n",
    "\n",
    "class TaxonomyGenerationState(TypedDict):\n",
    "    # The raw docs; we inject summaries within them in the first step\n",
    "    documents: List[Doc]\n",
    "    # Indices to be concise\n",
    "    minibatches: List[List[int]]\n",
    "    # Candidate Taxonomes (full trajectory)\n",
    "    clusters: Annotated[List[List[dict]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize docs\n",
    "\n",
    "Chat logs can get quite long. Our taxonomy generation step needs to see large, diverse minibatches to be able to adequately capture the distribution of categories. To ensure they can all fit efficiently into the context window, we first summarize each chat log. Downstream steps will use these summaries instead of the raw doc content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda, RunnablePassthrough\n",
    "\n",
    "summary_prompt = hub.pull(\"wfh/tnt-llm-summary-generation\").partial(\n",
    "    summary_prompt=20, explanation_length=30\n",
    ")\n",
    "\n",
    "def parse_summary(xml_string: str) -> dict:\n",
    "    summary_pattern = r\"<summary>(.*?)</summary>\"\n",
    "    explanation_pattern = r\"<explanation>(.*?)</explanation>\"\n",
    "\n",
    "    summary_match = re.search(summary_pattern, xml_string, re.DOTALL)\n",
    "    explanation_match = re.search(explanation_pattern, xml_string, re.DOTALL)\n",
    "\n",
    "    summary = summary_match.group(1).strip() if summary_match else \"\"\n",
    "    explanation = explanation = explanation_match.group(1).strip() if explanation_match else \"\"\n",
    "\n",
    "    return {\"summary\": summary, \"explanation\": explanation}\n",
    "\n",
    "summary_llm_chain = (\n",
    "    summary_prompt\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    "    # Customise the tracking name for easier organization\n",
    ").with_config(run_name=\"GenerateSummary\")\n",
    "summary_chain = summary_llm_chain | parse_summary\n",
    "\n",
    "# Now combine as a \"map\" operation in a map-reduce chain \n",
    "# Input: state\n",
    "# Output: state U summaries\n",
    "# Processes docs in parallel\n",
    "def get_content(state: TaxonomyGenerationState):\n",
    "    docs = state['documents']\n",
    "    return [{\"content\": doc['content']} for doc in docs]\n",
    "\n",
    "map_step = RunnablePassthrough.assign(\n",
    "    summaries=get_content\n",
    "    # This effectively creates a \"map\" operation\n",
    "    # Note you can make this more robust by handling individual errors\n",
    "    | RunnableLambda(func=summary_chain.batch, afunc=summary_chain.abatch)\n",
    ")\n",
    "\n",
    "def reduce_summaries(combined: dict) -> TaxonomyGenerationState:\n",
    "    summaries = combined['summaries']\n",
    "    documents = combined['documents']\n",
    "    return {\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"id\": doc['id'],\n",
    "                \"content\": doc['content'],\n",
    "                \"summary\": summ_info['summary'],\n",
    "                \"explanation\": summ_info['explanation'],\n",
    "            }\n",
    "            for doc, summ_info in zip(documents, summaries)\n",
    "        ]\n",
    "    }\n",
    "map_reduce_chain = map_step | reduce_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Minibatches\n",
    "\n",
    "Each minibatch contains a random sample of docs. This lets the flow identify inadequacies in the current taxonomy using new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_minibatches(state: TaxonomyGenerationState, config: RunnableConfig):\n",
    "    batch_size = config['configurable'].get(\"batch_size\", 200)\n",
    "    original = state['documents']\n",
    "    indices = list(range(len(original)))\n",
    "    random.shuffle(indices)\n",
    "    if len(indices) < batch_size:\n",
    "        # Don't pad needlessly if we can't fill a single batch\n",
    "        return [indices]\n",
    "    \n",
    "    num_full_batches = len(indices) // batch_size\n",
    "\n",
    "    batches = [\n",
    "        indices[i * batch_size: (i+1) * batch_size] for i in range(num_full_batches)\n",
    "    ]\n",
    "    leftovers = len(indices) % batch_size\n",
    "    if leftovers:\n",
    "        last_batch = indices[num_full_batches * batch_size :]\n",
    "        elements_to_add = batch_size - leftovers\n",
    "        last_batch += random.sample(indices, elements_to_add)\n",
    "        batches.append(last_batch)\n",
    "\n",
    "    return {\n",
    "        \"minibatches\": batches,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy Generation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "def parse_taxa(output_text: str) -> Dict:\n",
    "    \"\"\"Extract the taxonomy from the generated output.\"\"\"\n",
    "    cluster_matches = re.findall(\n",
    "        r\"\\s*<id>(.*?)</id>\\s*<name>(.*?)</name>\\s*<description>(.*?)</description>\\s*\",\n",
    "        output_text,\n",
    "        re.DOTALL,\n",
    "    )\n",
    "    clusters = [\n",
    "        {'id': id.strip(), \"name\": name.strip(), \"description\": description.strip()}\n",
    "        for id, name, description in cluster_matches\n",
    "    ]\n",
    "    # We don't parse the explanation since it isn't used downstream\n",
    "    return {'clusters': clusters}\n",
    "\n",
    "def format_docs(docs: List[Doc]) -> str:\n",
    "    xml_table = \"<conversation>\\n\"\n",
    "    for doc in docs:\n",
    "        xml_table += f'<conv_summ id={doc[\"id\"]}>{doc[\"summary\"]}</conv_summ>\\n'\n",
    "    xml_table +=\"</conversation>\"\n",
    "    return xml_table\n",
    "\n",
    "def format_taxonomy(clusters):\n",
    "    xml = \"<cluster_table>\\n\"\n",
    "    for label in clusters:\n",
    "        xml += \"  <cluster>\\n\"\n",
    "        xml += f'    <id>{label[\"id\"]}</id>\\n'\n",
    "        xml += f'    <name>{label[\"name\"]}</name>\\n'\n",
    "        xml += f'    <description>{label[\"description\"]}</description>\\n'\n",
    "        xml += \"  </cluster>\\n\"\n",
    "    xml += \"</cluster_table>\"\n",
    "    return xml\n",
    "\n",
    "def invoke_taxonomy_chain(\n",
    "        chain: Runnable,\n",
    "        state: TaxonomyGenerationState,\n",
    "        config: RunnableConfig,\n",
    "        mb_indices: List[int],\n",
    ") -> TaxonomyGenerationState:\n",
    "    configurable = config['configurable']\n",
    "    docs = state['documents']\n",
    "    minibatch = [docs[idx] for idx in mb_indices]\n",
    "    data_table_xml = format_docs(minibatch)\n",
    "\n",
    "    previous_taxonomy = state['clusters'][-1] if state['clusters'] else []\n",
    "    cluster_table_xml = format_taxonomy(previous_taxonomy)\n",
    "\n",
    "    updated_taxonomy = chain.invoke(\n",
    "        {\"data_xml\": data_table_xml,\n",
    "         \"use_case\": configurable['use_case'],\n",
    "         \"cluster_table_xml\": cluster_table_xml,\n",
    "         \"suggestion_length\": configurable.get(\"suggestion_length\", 30),\n",
    "         \"cluster_name_length\": configurable.get(\"cluster_name_length\", 10),\n",
    "         \"cluster_description_length\": configurable.get(\"cluster_description_length\", 30),\n",
    "         \"explanation_length\": configurable.get(\"explanation_length\", 20),\n",
    "         \"max_num_clusters\": configurable.get(\"max_num_clusters\", 25)\n",
    "         }\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"clusters\": [updated_taxonomy['clusters']],\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate initial taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/llm/lib/python3.11/site-packages/langchain_core/utils/utils.py:234: UserWarning: WARNING! max_tokens_to_sample is not default parameter.\n",
      "                max_tokens_to_sample was transferred to model_kwargs.\n",
      "                Please confirm that max_tokens_to_sample is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We will share an LLM for each step of the generate -> update -> review cycle\n",
    "taxonomy_generation_llm = ChatOpenAI(model=\"gpt-4o\", max_tokens_to_sample=2000)\n",
    "\n",
    "# Initial generation\n",
    "taxonomy_generation_prompt = hub.pull(\"wfh/tnt-llm-taxonomy-generation\").partial(\n",
    "    use_case='Generate the taxonomy that can be used to label the user intent in the conversation.',\n",
    ")\n",
    "\n",
    "taxa_gen_llm_chain = (\n",
    "    taxonomy_generation_prompt | taxonomy_generation_llm | StrOutputParser()\n",
    ").with_config(run_name='GenerateTaxonomy')\n",
    "\n",
    "generate_taxonomy_chain = taxa_gen_llm_chain | parse_taxa\n",
    "\n",
    "def generate_taxonomy(\n",
    "        state: TaxonomyGenerationState, config: RunnableConfig\n",
    ") -> TaxonomyGenerationState:\n",
    "    return invoke_taxonomy_chain(\n",
    "        generate_taxonomy_chain, state, config=state['minibatches'][0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_update_prompt = hub.pull(\"wfh/tnt-llm-taxonomy-update\")\n",
    "\n",
    "taxa_update_llm_chain = (\n",
    "    taxonomy_update_prompt | taxonomy_generation_llm | StrOutputParser()\n",
    ").with_config(run_name='UpdateTaxonomy')\n",
    "\n",
    "update_taxonomy_chain = taxa_update_llm_chain | parse_taxa\n",
    "\n",
    "def update_taxonomy(\n",
    "        state: TaxonomyGenerationState, config: RunnableConfig\n",
    ") -> TaxonomyGenerationState:\n",
    "    which_mb = len(state['clusters']) % len(state['minibatches'])\n",
    "    return invoke_taxonomy_chain(\n",
    "        update_taxonomy_chain, state, config, state['minibatches'][which_mb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_review_prompt = hub.pull(\"wfh/tnt-llm-taxonomy-review\")\n",
    "taxa_review_llm_chain = (\n",
    "    taxonomy_review_prompt | taxonomy_generation_llm | StrOutputParser()\n",
    ").with_config(run_name='ReviewTaxonomy')\n",
    "\n",
    "review_taxonomy_chain = taxa_review_llm_chain | parse_taxa\n",
    "\n",
    "def review_taxonomy(\n",
    "        state: TaxonomyGenerationState, config: RunnableConfig\n",
    ") -> TaxonomyGenerationState:\n",
    "    batch_size = config['configurable'].get(\"batch_size\", 200)\n",
    "    original = state['documents']\n",
    "    indices = list(range(len(original)))\n",
    "    random.shuffle(indices)\n",
    "    return invoke_taxonomy_chain(\n",
    "        review_taxonomy_chain, state, config, indices[:batch_size]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph = StateGraph(TaxonomyGenerationState)\n",
    "graph.add_node(\"summarize\", map_reduce_chain)\n",
    "graph.add_node(\"get_minibatches\", get_minibatches)\n",
    "graph.add_node(\"generate_taxonomy\", generate_taxonomy)\n",
    "graph.add_node(\"update_taxonomy\", update_taxonomy)\n",
    "graph.add_node(\"review_taxonomy\", review_taxonomy)\n",
    "\n",
    "graph.add_edge('summarize', 'get_minibatches')\n",
    "graph.add_edge(\"get_minibatches\", \"generate_taxonomy\")\n",
    "graph.add_edge(\"generate_taxonomy\", 'update_taxonomy')\n",
    "\n",
    "def should_review(state: TaxonomyGenerationState) -> str:\n",
    "    num_minibatches = len(state['minibatches'])\n",
    "    num_revisions = len(state['clusters'])\n",
    "    if num_revisions < num_minibatches:\n",
    "        return \"update_taxonomy\"\n",
    "    return \"review_taxonomy\"\n",
    "graph.add_conditional_edges(\n",
    "    \"update_taxonomy\",\n",
    "    should_review,\n",
    "    # Optional (but required for the diagram to be drawn correctly below)\n",
    "    {\"update_taxonomy\": \"update_taxonomy\", 'review_taxonomy': \"review_taxonomy\"},\n",
    ")\n",
    "graph.add_edge('review_taxonomy', END)\n",
    "graph.add_edge(START, 'summarize')\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download customer reviews for a products\n",
    "\n",
    "# Kaggle Credentials\n",
    "\n",
    "I don't want to use google drive here, so i decided to use Kaggle API to directly  download dataset from Kaggle competition page.\n",
    "For this:\n",
    "\n",
    "* First, you need to install the Kaggle API by running the following command in a code cell:   \n",
    "\n",
    "\n",
    "```\n",
    "!pip install kaggle\n",
    "```\n",
    "\n",
    "* Next, you need to download your Kaggle API key. To do this, go to your Kaggle account settings page, scroll down to the \"API\" section, and click on the \"Create New API Token\" button. This will download a JSON file with your Kaggle API credentials.  \n",
    "link: https://www.machinelearningmindset.com/kaggle-dataset-in-google-colab/\n",
    "\n",
    "\n",
    "* Upload your Kaggle API key to Jupyter Notebook by clicking on the \"Files\" tab on the left-hand side of the Colab interface, then click on \"Upload\" and select the JSON file containing your Kaggle API credentials.\n",
    "\n",
    "* Run the following commands in a code cell to authenticate the Kaggle API:\n",
    "\n",
    "\n",
    "```\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"your_kaggle_username\"\n",
    "os.environ['KAGGLE_KEY'] = \"your_kaggle_api_key\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews\n",
      "License(s): CC0-1.0\n",
      "Downloading womens-ecommerce-clothing-reviews.zip to /Users/azamatkuzdibayev/train/llm/projects/Text-mining-at-Scale-for-taxonomy\n",
      " 72%|███████████████████████████▎          | 2.00M/2.79M [00:00<00:00, 3.18MB/s]\n",
      "100%|██████████████████████████████████████| 2.79M/2.79M [00:00<00:00, 3.74MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading dataset from kaggle\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "!kaggle datasets download -d nicapotato/womens-ecommerce-clothing-reviews\n",
    "\n",
    "\n",
    "\n",
    "# Unzip journey-springfield.zip\n",
    "with zipfile.ZipFile(\"womens-ecommerce-clothing-reviews.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping  data...\") \n",
    "    zip_ref.extractall()\n",
    "    print(\"Unzipping complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df  = pd.read_csv(\"./Womens Clothing E-Commerce Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>23481</td>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>23482</td>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>23483</td>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>23484</td>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>23485</td>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23486 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Clothing ID  Age  \\\n",
       "0               0          767   33   \n",
       "1               1         1080   34   \n",
       "2               2         1077   60   \n",
       "3               3         1049   50   \n",
       "4               4          847   47   \n",
       "...           ...          ...  ...   \n",
       "23481       23481         1104   34   \n",
       "23482       23482          862   48   \n",
       "23483       23483         1104   31   \n",
       "23484       23484         1084   28   \n",
       "23485       23485         1104   52   \n",
       "\n",
       "                                                   Title  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                Some major design flaws   \n",
       "3                                       My favorite buy!   \n",
       "4                                       Flattering shirt   \n",
       "...                                                  ...   \n",
       "23481                     Great dress for many occasions   \n",
       "23482                         Wish it was made of cotton   \n",
       "23483                              Cute, but see through   \n",
       "23484  Very cute dress, perfect for summer parties an...   \n",
       "23485                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "0      Absolutely wonderful - silky and sexy and comf...       4   \n",
       "1      Love this dress!  it's sooo pretty.  i happene...       5   \n",
       "2      I had such high hopes for this dress and reall...       3   \n",
       "3      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "4      This shirt is very flattering to all due to th...       5   \n",
       "...                                                  ...     ...   \n",
       "23481  I was very happy to snag this dress at such a ...       5   \n",
       "23482  It reminds me of maternity clothes. soft, stre...       3   \n",
       "23483  This fit well, but the top was very see throug...       3   \n",
       "23484  I bought this dress for a wedding i have this ...       3   \n",
       "23485  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0                    1                        0       Initmates   \n",
       "1                    1                        4         General   \n",
       "2                    0                        0         General   \n",
       "3                    1                        0  General Petite   \n",
       "4                    1                        6         General   \n",
       "...                ...                      ...             ...   \n",
       "23481                1                        0  General Petite   \n",
       "23482                1                        0  General Petite   \n",
       "23483                0                        1  General Petite   \n",
       "23484                1                        2         General   \n",
       "23485                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \n",
       "0            Intimate  Intimates  \n",
       "1             Dresses    Dresses  \n",
       "2             Dresses    Dresses  \n",
       "3             Bottoms      Pants  \n",
       "4                Tops    Blouses  \n",
       "...               ...        ...  \n",
       "23481         Dresses    Dresses  \n",
       "23482            Tops      Knits  \n",
       "23483         Dresses    Dresses  \n",
       "23484         Dresses    Dresses  \n",
       "23485         Dresses    Dresses  \n",
       "\n",
       "[23486 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
